{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: gld@cunixb.cc.columbia.edu (Gary L Dare)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: vzhivov@superior.carleton.ca (Vladimir Z...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  From: gld@cunixb.cc.columbia.edu (Gary L Dare)...\n",
       "1  From: atterlep@vela.acs.oakland.edu (Cardinal ...\n",
       "2  From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...\n",
       "3  From: atterlep@vela.acs.oakland.edu (Cardinal ...\n",
       "4  From: vzhivov@superior.carleton.ca (Vladimir Z..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data', sep=\",\", header=None)\n",
    "\n",
    "data.columns = ['text']\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is a collection of emails that are not labelled. Let's try extract topics from them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‡ You're used to it by now... Clean up! Store the cleaned text in a new dataframe column \"clean_text\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TextNormalizer(text):\n",
    "    \n",
    "    for i in range(len(text)):\n",
    "        clean_text =  text[i].strip()\n",
    "        clean_text = clean_text.lower()\n",
    "        whitelist = set(\"'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ \")\n",
    "        clean_text = ''.join(filter(whitelist.__contains__, clean_text))\n",
    "        clean_text = clean_text.strip()\n",
    "        text[i] = clean_text\n",
    "\n",
    "    return text\n",
    "\n",
    "data['clean_text'] = TextNormalizer(data.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‡ Train an LDA model to extract potential topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# create English stop words list\n",
    "en_stop = stopwords.words('english')\n",
    "\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = WordNetLemmatizer()\n",
    "\n",
    "# list for tokenized documents in loop\n",
    "texts = []\n",
    "\n",
    "# loop through document list\n",
    "for i in data.clean_text:\n",
    "    \n",
    "    # clean and tokenize document string\n",
    "    raw = i.lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "\n",
    "    # remove stop words from tokens\n",
    "    stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "    \n",
    "    # stem tokens\n",
    "    stemmed_tokens = [p_stemmer.lemmatize(i) for i in stopped_tokens]\n",
    "    \n",
    "    # add tokens to list\n",
    "    texts.append(stemmed_tokens)\n",
    "\n",
    "# turn our tokenized documents into a id <-> term dictionary\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "    \n",
    "# convert tokenized documents into a document-term matrix\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# generate LDA model\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=4, id2word = dictionary, passes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['william', 'still', 'really', 'allwill', 'dallas']\n"
     ]
    }
   ],
   "source": [
    "str_match = [s for s in tokens if \"ll\" in s]\n",
    "print(str_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0061606 , 0.9938394 ],\n",
       "       [0.00410111, 0.99589889],\n",
       "       [0.00387489, 0.99612511],\n",
       "       ...,\n",
       "       [0.00461547, 0.99538453],\n",
       "       [0.02715464, 0.97284536],\n",
       "       [0.98987665, 0.01012335]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "vectorizer.fit(data.clean_text)\n",
    "vector = vectorizer.transform(data.clean_text)\n",
    "lda=LDA(n_components=2)\n",
    "lda.fit_transform(vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize potential topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‡ The function to print the words associated with the potential topics is already made for you. You just have to pass the correct arguments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.010*\"god\" + 0.006*\"one\" + 0.006*\"would\" + 0.005*\"people\" + 0.004*\"christian\" + 0.004*\"jesus\" + 0.004*\"say\" + 0.003*\"think\" + 0.003*\"church\" + 0.003*\"know\"'), (1, '0.008*\"team\" + 0.008*\"game\" + 0.005*\"hockey\" + 0.004*\"player\" + 0.004*\"university\" + 0.004*\"play\" + 0.004*\"would\" + 0.004*\"year\" + 0.003*\"go\" + 0.003*\"nhl\"')]\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topics(num_topics=4, num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topic(model, count_vectorizer, n_top_words):\n",
    "    words = count_vectorizer.get_feature_names()\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print('\\nTopic #%d:'%  idx)\n",
    "        print([(words[i], (topic[i]/np.sum(topic)).round(4)) for i in topic.argsort()[:-n_top_words - 1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx, topic =lda.components_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112280.10773156365"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.sum(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic #0:\n",
      "[('god', 0.0039), ('don', 0.0038), ('church', 0.0032), ('like', 0.0031), ('think', 0.003), ('people', 0.0028), ('time', 0.0027), ('university', 0.0026), ('just', 0.0026), ('hockey', 0.0025)]\n",
      "\n",
      "Topic #1:\n",
      "[('people', 0.0058), ('god', 0.0055), ('truth', 0.0044), ('know', 0.0043), ('think', 0.0038), ('don', 0.0035), ('article', 0.0034), ('university', 0.0033), ('believe', 0.0032), ('christians', 0.0031)]\n",
      "\n",
      "Topic #2:\n",
      "[('god', 0.015), ('jesus', 0.0072), ('people', 0.0054), ('christ', 0.0042), ('does', 0.0041), ('believe', 0.004), ('hell', 0.0035), ('think', 0.0034), ('say', 0.0033), ('church', 0.0033)]\n",
      "\n",
      "Topic #3:\n",
      "[('team', 0.0085), ('game', 0.0063), ('hockey', 0.006), ('play', 0.0053), ('games', 0.0042), ('nhl', 0.0041), ('season', 0.0039), ('year', 0.0037), ('period', 0.0034), ('university', 0.0033)]\n"
     ]
    }
   ],
   "source": [
    "number_words = 10\n",
    "print_topic(lda, vectorizer, number_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict topic of new text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‡ You can now use your LDA model to predict the topic of a new text. First, use your vectorizer to vectorize the example. Then, use your LDA model to predict the topic of the vectorized example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text='The National Basketball Association (NBA) is the premier basketball league in the world \n",
    "Created on June 6, 1946 under the name of BAA (Basketball Association of America), \n",
    "the league was renamed NBA in 1949 after its merger with the NBL (National Basketball League) 1.\n",
    "It is one of the four major professional leagues in American sports, alongside the NFL (American football), \n",
    "MLB (baseball) and NHL (ice hockey). The headquarters of the NBA are located in the Olympic Tower at 645 5th Avenue in New York2.\n",
    "In 2015, NBA players were the highest paid athletes in the world3'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
